<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.0">
<title>julius.fftconv API documentation</title>
<meta name="description" content="Implementation of a FFT based 1D convolution in PyTorch.
While FFT is used in CUDNN for small kernel sizes, it is not the case for long ones, e.g …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>julius.fftconv</code></h1>
</header>
<section id="section-intro">
<p>Implementation of a FFT based 1D convolution in PyTorch.
While FFT is used in CUDNN for small kernel sizes, it is not the case for long ones, e.g. 512.
This module implements efficient FFT based convolutions for such convolutions. A typical
application is for evaluationg FIR filters with a long receptive field, typically
evaluated with a stride of 1.</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="julius.fftconv.fft_conv1d"><code class="name flex">
<span>def <span class="ident">fft_conv1d</span></span>(<span>input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, stride: int = 1, padding: int = 0, block_ratio: float = 5)</span>
</code></dt>
<dd>
<div class="desc"><p>Same as <code>torch.nn.functional.conv1d</code> but using FFT for the convolution.
Please check PyTorch documentation for more information.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>input signal of shape <code>[B, C, T]</code>.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>weight of the convolution <code>[D, C, K]</code> with <code>D</code> the number
of output channels.</dd>
<dt><strong><code>bias</code></strong> :&ensp;<code>Tensor</code> or <code>None</code></dt>
<dd>if not None, bias term for the convolution.</dd>
<dt><strong><code>stride</code></strong> :&ensp;<code>int</code></dt>
<dd>stride of convolution.</dd>
<dt><strong><code>padding</code></strong> :&ensp;<code>int</code></dt>
<dd>padding to apply to the input.</dd>
<dt><strong><code>block_ratio</code></strong> :&ensp;<code>float</code></dt>
<dd>can be tuned for speed. The input is splitted in chunks
with a size of <code>int(block_ratio * kernel_size)</code>.</dd>
</dl>
<h2 id="shape">Shape</h2>
<ul>
<li>Inputs: <code>input</code> is <code>[B, C, T]</code>, <code>weight</code> is <code>[D, C, K]</code> and bias is <code>[D]</code>.</li>
<li>Output: <code>(*, T)</code></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is faster than <code>torch.nn.functional.conv1d</code> only in specific cases.
Typically, the kernel size should be of the order of 256 to see any real gain,
for a stride of 1.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Dilation and groups are not supported at the moment. This function might use
more memory than the default Conv1d implementation.</p>
</div></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="julius.fftconv.FFTConv1d"><code class="flex name class">
<span>class <span class="ident">FFTConv1d</span></span>
<span>(</span><span>in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, bias: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Same as <code>torch.nn.Conv1d</code> but based on <code><a title="julius.fftconv.fft_conv1d" href="#julius.fftconv.fft_conv1d">fft_conv1d()</a></code>.
Please check PyTorch documentation for more information.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>in_channels</code></strong> :&ensp;<code>int</code></dt>
<dd>number of input channels.</dd>
<dt><strong><code>out_channels</code></strong> :&ensp;<code>int</code></dt>
<dd>number of output channels.</dd>
<dt><strong><code>kernel_size</code></strong> :&ensp;<code>int</code></dt>
<dd>kernel size of convolution.</dd>
<dt><strong><code>stride</code></strong> :&ensp;<code>int</code></dt>
<dd>stride of convolution.</dd>
<dt><strong><code>padding</code></strong> :&ensp;<code>int</code></dt>
<dd>padding to apply to the input.</dd>
<dt><strong><code>bias</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, use a bias term.</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This module is faster than <code>torch.nn.Conv1d</code> only in specific cases.
Typically, <code>kernel_size</code> should be of the order of 256 to see any real gain,
for a stride of 1.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Dilation and groups are not supported at the moment. This module might use
more memory than the default Conv1d implementation.</p>
</div>
<pre><code class="language-python-repl">&gt;&gt;&gt; fftconv = FFTConv1d(12, 24, 128, 4)
&gt;&gt;&gt; x = torch.randn(4, 12, 1024)
&gt;&gt;&gt; print(list(fftconv(x).shape))
[4, 24, 225]
</code></pre>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/adefossez/julius/blob/126d7eea519875e43c4bd61435b9185ace5df24c/julius/fftconv.py#L138-L183" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class FFTConv1d(torch.nn.Module):
    &#34;&#34;&#34;
    Same as `torch.nn.Conv1d` but based on `fft_conv1d`.
    Please check PyTorch documentation for more information.

    Args:
        in_channels (int): number of input channels.
        out_channels (int): number of output channels.
        kernel_size (int): kernel size of convolution.
        stride (int): stride of convolution.
        padding (int): padding to apply to the input.
        bias (bool): if True, use a bias term.

    ..note::
        This module is faster than `torch.nn.Conv1d` only in specific cases.
        Typically, `kernel_size` should be of the order of 256 to see any real gain,
        for a stride of 1.

    ..warning::
        Dilation and groups are not supported at the moment. This module might use
        more memory than the default Conv1d implementation.

    &gt;&gt;&gt; fftconv = FFTConv1d(12, 24, 128, 4)
    &gt;&gt;&gt; x = torch.randn(4, 12, 1024)
    &gt;&gt;&gt; print(list(fftconv(x).shape))
    [4, 24, 225]
    &#34;&#34;&#34;
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int,
                 stride: int = 1, padding: int = 0, bias: bool = True):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding

        conv = torch.nn.Conv1d(in_channels, out_channels, kernel_size, bias=bias)
        self.weight = conv.weight
        self.bias = conv.bias

    def forward(self, input: torch.Tensor):
        return fft_conv1d(
            input, self.weight, self.bias, self.stride, self.padding)

    def __repr__(self):
        return simple_repr(self, overrides={&#34;bias&#34;: self.bias is not None})</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="julius.fftconv.FFTConv1d.call_super_init"><code class="name">var <span class="ident">call_super_init</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="julius.fftconv.FFTConv1d.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="julius.fftconv.FFTConv1d.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="julius.fftconv.FFTConv1d.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, input: torch.Tensor) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="julius" href="index.html">julius</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="julius.fftconv.fft_conv1d" href="#julius.fftconv.fft_conv1d">fft_conv1d</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="julius.fftconv.FFTConv1d" href="#julius.fftconv.FFTConv1d">FFTConv1d</a></code></h4>
<ul class="">
<li><code><a title="julius.fftconv.FFTConv1d.call_super_init" href="#julius.fftconv.FFTConv1d.call_super_init">call_super_init</a></code></li>
<li><code><a title="julius.fftconv.FFTConv1d.dump_patches" href="#julius.fftconv.FFTConv1d.dump_patches">dump_patches</a></code></li>
<li><code><a title="julius.fftconv.FFTConv1d.forward" href="#julius.fftconv.FFTConv1d.forward">forward</a></code></li>
<li><code><a title="julius.fftconv.FFTConv1d.training" href="#julius.fftconv.FFTConv1d.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.0</a>.</p>
</footer>
</body>
</html>
